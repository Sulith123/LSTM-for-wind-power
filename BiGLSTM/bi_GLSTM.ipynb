{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78cb7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, json, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5344dbe",
   "metadata": {},
   "source": [
    "### Data handling and feature engieering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a32be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns & Base Features\n",
    "TIME_COL   = \"TIMESTAMP\"\n",
    "TARGET_COL = \"TARGETVAR\"\n",
    "BASE_FEATS = [\"U10\", \"V10\", \"U100\", \"V100\"]\n",
    "\n",
    "# engineered & lag features (non-leaky)\n",
    "LAGS_Y       = [1, 3, 6, 12, 24]\n",
    "LAGS_SPEED   = [1, 3, 6]\n",
    "ROLLS_Y      = [6, 12, 24]\n",
    "\n",
    "# turbulence (can be toggled by GA)\n",
    "TURB_WINS    = [6, 12, 24, 48]\n",
    "\n",
    "# splits\n",
    "TRAIN_RATIO  = 0.70\n",
    "VAL_RATIO    = 0.15  # test ≈ 0.15\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===================== Small utils =====================\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def smape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    return 100.0 * np.mean(2.0 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true) + eps))\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# ===================== Data =====================\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    # Uses CLI-provided path. Supports Excel/CSV.\n",
    "    if file_path.lower().endswith((\".xlsx\", \".xls\")):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)\n",
    "    df[TIME_COL] = pd.to_datetime(df[TIME_COL], infer_datetime_format=True, errors=\"coerce\")\n",
    "    df = df.sort_values(TIME_COL).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def add_engineered_features(df: pd.DataFrame, include_turbulence: bool) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    # wind speed & direction\n",
    "    out[\"speed10\"]  = np.sqrt(out[\"U10\"]**2  + out[\"V10\"]**2)\n",
    "    out[\"speed100\"] = np.sqrt(out[\"U100\"]**2 + out[\"V100\"]**2)\n",
    "    dir10  = np.arctan2(out[\"V10\"],  out[\"U10\"])\n",
    "    dir100 = np.arctan2(out[\"V100\"], out[\"U100\"])\n",
    "    out[\"dir10_sin\"], out[\"dir10_cos\"]   = np.sin(dir10),  np.cos(dir10)\n",
    "    out[\"dir100_sin\"], out[\"dir100_cos\"] = np.sin(dir100), np.cos(dir100)\n",
    "    # shear & veer\n",
    "    out[\"shear_speed\"] = out[\"speed100\"] - out[\"speed10\"]\n",
    "    veer = dir100 - dir10\n",
    "    out[\"veer_sin\"], out[\"veer_cos\"] = np.sin(veer), np.cos(veer)\n",
    "    # time (cyclic)\n",
    "    out[\"hour\"] = out[TIME_COL].dt.hour\n",
    "    out[\"day\"]  = out[TIME_COL].dt.dayofyear\n",
    "    out[\"hour_sin\"] = np.sin(2*np.pi*out[\"hour\"]/24.0)\n",
    "    out[\"hour_cos\"] = np.cos(2*np.pi*out[\"hour\"]/24.0)\n",
    "    out[\"day_sin\"]  = np.sin(2*np.pi*out[\"day\"]/366.0)\n",
    "    out[\"day_cos\"]  = np.cos(2*np.pi*out[\"day\"]/366.0)\n",
    "    # target lags (shifted)\n",
    "    for L in LAGS_Y:\n",
    "        out[f\"y_lag{L}\"] = out[TARGET_COL].shift(L)\n",
    "    # rolling means of y (shift before rolling)\n",
    "    for W in ROLLS_Y:\n",
    "        out[f\"y_roll{W}\"] = out[TARGET_COL].shift(1).rolling(W, min_periods=W).mean()\n",
    "    # speed lags\n",
    "    for L in LAGS_SPEED:\n",
    "        out[f\"speed10_lag{L}\"]  = out[\"speed10\"].shift(L)\n",
    "        out[f\"speed100_lag{L}\"] = out[\"speed100\"].shift(L)\n",
    "    # turbulence / gustiness (shifted to avoid leakage)\n",
    "    if include_turbulence:\n",
    "        for W in TURB_WINS:\n",
    "            s10  = out[\"speed10\"].shift(1).rolling(W, min_periods=W)\n",
    "            s100 = out[\"speed100\"].shift(1).rolling(W, min_periods=W)\n",
    "            out[f\"speed10_std{W}\"]  = s10.std()\n",
    "            out[f\"speed100_std{W}\"] = s100.std()\n",
    "            out[f\"speed10_rng{W}\"]  = s10.max() - s10.min()\n",
    "            out[f\"speed100_rng{W}\"] = s100.max() - s100.min()\n",
    "            out[f\"y_std{W}\"]        = out[TARGET_COL].shift(1).rolling(W, min_periods=W).std()\n",
    "    return out\n",
    "\n",
    "def build_feat_list(include_turbulence: bool):\n",
    "    base = (\n",
    "        BASE_FEATS +\n",
    "        [\"speed10\",\"speed100\",\"dir10_sin\",\"dir10_cos\",\"dir100_sin\",\"dir100_cos\",\n",
    "         \"shear_speed\",\"veer_sin\",\"veer_cos\",\"hour_sin\",\"hour_cos\",\"day_sin\",\"day_cos\"] +\n",
    "        [f\"y_lag{L}\" for L in LAGS_Y] +\n",
    "        [f\"y_roll{W}\" for W in ROLLS_Y] +\n",
    "        [f\"speed10_lag{L}\" for L in LAGS_SPEED] +\n",
    "        [f\"speed100_lag{L}\" for L in LAGS_SPEED]\n",
    "    )\n",
    "    if not include_turbulence:\n",
    "        return base\n",
    "    turb = (\n",
    "        [f\"speed10_std{W}\"  for W in TURB_WINS] +\n",
    "        [f\"speed100_std{W}\" for W in TURB_WINS] +\n",
    "        [f\"speed10_rng{W}\"  for W in TURB_WINS] +\n",
    "        [f\"speed100_rng{W}\" for W in TURB_WINS] +\n",
    "        [f\"y_std{W}\"        for W in TURB_WINS]\n",
    "    )\n",
    "    return base + turb\n",
    "\n",
    "def make_sequences(X, y, lookback):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(lookback, len(X)):\n",
    "        Xs.append(X[i-lookback:i, :])\n",
    "        ys.append(y[i, 0])\n",
    "    return np.array(Xs, np.float32), np.array(ys, np.float32).reshape(-1,1)\n",
    "\n",
    "def batch_iter(X, y, batch_size, shuffle):\n",
    "    n = len(X)\n",
    "    idx = np.arange(n)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    for i in range(0, n, batch_size):\n",
    "        b = idx[i:i+batch_size]\n",
    "        yield torch.from_numpy(X[b]).float(), torch.from_numpy(y[b]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6bb63b",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5782030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_components(input_size, hidden, layers, dropout, bidir):\n",
    "    \"\"\"\n",
    "    initlaize the lstm model\n",
    "    Then the output from the model is linearized \n",
    "    lin1,lin2 - linear fully connceted layers \n",
    "    lin2 - projects the output to the desired size which is 1\n",
    "    \"\"\"\n",
    "    lstm = nn.LSTM(input_size=input_size,\n",
    "                   hidden_size=hidden,\n",
    "                   num_layers=layers,\n",
    "                   batch_first=True,\n",
    "                   dropout=dropout if layers > 1 else 0.0,\n",
    "                   bidirectional=bidir).to(DEVICE)\n",
    "    out_size = hidden * (2 if bidir else 1)\n",
    "    norm = nn.LayerNorm(out_size).to(DEVICE)\n",
    "    lin1 = nn.Linear(out_size, out_size).to(DEVICE)\n",
    "    lin2 = nn.Linear(out_size, 1).to(DEVICE)\n",
    "    return {\"lstm\": lstm, \"norm\": norm, \"lin1\": lin1, \"lin2\": lin2, \"dropout\": dropout}\n",
    "\n",
    "def set_train_mode(mods, train: bool):\n",
    "    \"since pytorch model behaves different during training and validation need to specifically define the mode\"\n",
    "    for m in [mods[\"lstm\"], mods[\"norm\"], mods[\"lin1\"], mods[\"lin2\"]]:\n",
    "        m.train(mode=train)\n",
    "\n",
    "def forward_pass(x, mods, training: bool):\n",
    "    # x: (B,T,F)\n",
    "    # B- batch size, T- no. of timestamps F- features in each timestep\n",
    "    o, _ = mods[\"lstm\"](x)               # (B,T,H*)\n",
    "    last = o[:, -1, :]                   # (B,H*)\n",
    "    last = mods[\"norm\"](last)            # (B,H*)\n",
    "    last = F.gelu(mods[\"lin1\"](last))    # (B,H*)\n",
    "    last = F.dropout(last, p=mods[\"dropout\"], training=training)\n",
    "    yhat = mods[\"lin2\"](last)            # (B,1)\n",
    "    return yhat\n",
    "\n",
    "def optimizer_for(mods, lr, weight_decay):\n",
    "    params = list(mods[\"lstm\"].parameters()) + \\\n",
    "             list(mods[\"norm\"].parameters()) + \\\n",
    "             list(mods[\"lin1\"].parameters()) + \\\n",
    "             list(mods[\"lin2\"].parameters())\n",
    "    return torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# ===================== Fold train (Val RMSE) =====================\n",
    "def train_fold(Xtr, ytr, Xva, yva, params, max_epochs, es_patience):\n",
    "    # scalers on train only\n",
    "    xsc = StandardScaler().fit(Xtr)\n",
    "    ysc = StandardScaler().fit(ytr)\n",
    "    Xtr_s, ytr_s = xsc.transform(Xtr), ysc.transform(ytr)\n",
    "    Xva_s, yva_s = xsc.transform(Xva), ysc.transform(yva)\n",
    "\n",
    "    lookback = params[\"lookback\"]\n",
    "    Xtr_seq, ytr_seq = make_sequences(Xtr_s, ytr_s, lookback)\n",
    "    Xva_seq, yva_seq = make_sequences(Xva_s, yva_s, lookback)\n",
    "    if len(Xtr_seq) < 16 or len(Xva_seq) < 16:\n",
    "        return float(\"inf\"), None  # degenerate\n",
    "\n",
    "    mods = build_components(Xtr_seq.shape[-1], params[\"hidden\"], params[\"layers\"],\n",
    "                            params[\"dropout\"], params[\"bidir\"])\n",
    "    opt  = optimizer_for(mods, params[\"lr\"], params[\"wd\"])\n",
    "    #sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=10, T_mult=2, eta_min=1e-5)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=0.5)\n",
    "\n",
    "    def inv_target(y_scaled):\n",
    "        y = ysc.inverse_transform(y_scaled).ravel()\n",
    "        if params[\"log_target\"]:\n",
    "            y = np.expm1(y)\n",
    "        return y\n",
    "\n",
    "    best = float(\"inf\"); no_improve = 0\n",
    "    best_state = {k: v.state_dict() for k, v in mods.items() if isinstance(v, nn.Module)}\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        # train\n",
    "        set_seed(epoch)  # small shake\n",
    "        set_train_mode(mods, True)\n",
    "        for xb, yb in batch_iter(Xtr_seq, ytr_seq, params[\"batch\"], shuffle=True):\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            pred = forward_pass(xb, mods, training=True)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            if params[\"clip\"] is not None:\n",
    "                nn.utils.clip_grad_norm_(\n",
    "                    list(mods[\"lstm\"].parameters()) + list(mods[\"lin1\"].parameters()) + list(mods[\"lin2\"].parameters()),\n",
    "                    params[\"clip\"]\n",
    "                )\n",
    "            opt.step()\n",
    "        #sched.step(epoch-1)\n",
    "\n",
    "        # validate (RMSE in original units)\n",
    "        set_train_mode(mods, False)\n",
    "        preds_s, trues_s = [], []\n",
    "        for xb, yb in batch_iter(Xva_seq, yva_seq, params[\"batch\"], shuffle=False):\n",
    "            with torch.no_grad():\n",
    "                pr = forward_pass(xb.to(DEVICE), mods, training=False).cpu().numpy()\n",
    "            preds_s.append(pr); trues_s.append(yb.numpy())\n",
    "        preds_s = np.vstack(preds_s); trues_s = np.vstack(trues_s)\n",
    "        y_pred = inv_target(preds_s)\n",
    "        y_true = inv_target(trues_s)\n",
    "        rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "        if rmse < best - 1e-6:\n",
    "            best = rmse; no_improve = 0\n",
    "            best_state = {k: v.state_dict() for k, v in mods.items() if isinstance(v, nn.Module)}\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= es_patience:\n",
    "                break\n",
    "\n",
    "    return best, (best_state, Xtr_seq.shape[-1])\n",
    "\n",
    "# ===================== Walk-forward CV =====================\n",
    "def make_walkforward_indices(n_total, n_test):\n",
    "    n_tv = n_total - n_test\n",
    "    cut1 = int(n_tv * 0.60); val1 = int(n_tv * 0.75)\n",
    "    cut2 = int(n_tv * 0.75); val2 = int(n_tv * 0.85)\n",
    "    cut3 = int(n_tv * 0.85); val3 = int(n_tv * 0.95)\n",
    "    folds = [\n",
    "        (0, cut1, cut1, val1),\n",
    "        (0, cut2, cut2, val2),\n",
    "        (0, cut3, cut3, val3),\n",
    "    ]\n",
    "    return folds, n_tv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3f18c",
   "metadata": {},
   "source": [
    "### Genetic algorithm\n",
    "\n",
    " Instead of manually trying different combinations of lookback and hidden layer sizes (h1, h2, h3), the GA automates  process by treating each combination as a \"genome\" and \"evolving\" a population of models over several generations to find the one with the best performance.\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../genetic.png\" alt=\"Diagram\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5408ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GA Search Space\n",
    "LOOKBACK_CHOICES = [12, 24, 36]\n",
    "H_CHOICES        = [64, 128]\n",
    "LAYERS_CHOICES   = [1, 2, 3]\n",
    "DROPOUT_CHOICES  = [0.0, 0.1]\n",
    "BATCH_CHOICES    = [64, 128, 256]\n",
    "BIDIR_CHOICES    = [True, False]\n",
    "LR_CHOICES       = [1e-4, 3e-4, 5e-4, 1e-3, 3e-3] \n",
    "WD_CHOICES       = [0.0, 1e-5, 1e-4]\n",
    "CLIP_CHOICES     = [None, 0.5, 1.0]\n",
    "BOOL_CHOICES     = [False, True]\n",
    "\n",
    "# Genome: indices into the above choice lists\n",
    "# [lookback_i, hidden_i, layers_i, dropout_i, batch_i, bidir_i, lr_i, wd_i, clip_i, log_target_i, turb_i]\n",
    "def random_individual():\n",
    "    return [\n",
    "        random.randrange(len(LOOKBACK_CHOICES)),\n",
    "        random.randrange(len(H_CHOICES)),\n",
    "        random.randrange(len(LAYERS_CHOICES)),\n",
    "        random.randrange(len(DROPOUT_CHOICES)),\n",
    "        random.randrange(len(BATCH_CHOICES)),\n",
    "        random.randrange(len(BIDIR_CHOICES)),\n",
    "        random.randrange(len(LR_CHOICES)),\n",
    "        random.randrange(len(WD_CHOICES)),\n",
    "        random.randrange(len(CLIP_CHOICES)),\n",
    "        random.randrange(len(BOOL_CHOICES)),  # log_target\n",
    "        random.randrange(len(BOOL_CHOICES)),  # include_turbulence\n",
    "    ]\n",
    "\n",
    "def decode(ind):\n",
    "    \"Converts the integer-based genome back into a human-readable dictionary of actual hyperparameter values\"\n",
    "    return {\n",
    "        \"lookback\": LOOKBACK_CHOICES[ind[0]],\n",
    "        \"hidden\":   H_CHOICES[ind[1]],\n",
    "        \"layers\":   LAYERS_CHOICES[ind[2]],\n",
    "        \"dropout\":  DROPOUT_CHOICES[ind[3]],\n",
    "        \"batch\":    BATCH_CHOICES[ind[4]],\n",
    "        \"bidir\":    BIDIR_CHOICES[ind[5]],\n",
    "        \"lr\":       LR_CHOICES[ind[6]],       # <— discrete LR\n",
    "        \"wd\":       WD_CHOICES[ind[7]],\n",
    "        \"clip\":     CLIP_CHOICES[ind[8]],\n",
    "        \"log_target\": BOOL_CHOICES[ind[9]],\n",
    "        \"turb_on\":    BOOL_CHOICES[ind[10]],\n",
    "    }\n",
    "\n",
    "def mutate(ind, mut_rate):\n",
    "    \" Introduce random changes to a genome to maintain genetic diversity\"\n",
    "    if random.random() < mut_rate:\n",
    "        g = random.randrange(len(ind))\n",
    "        # All genes are discrete indices now.\n",
    "        if g == 6:  # lr index\n",
    "            ind[6] = random.randrange(len(LR_CHOICES))\n",
    "        elif g == 0:\n",
    "            ind[0] = random.randrange(len(LOOKBACK_CHOICES))\n",
    "        elif g == 1:\n",
    "            ind[1] = random.randrange(len(H_CHOICES))\n",
    "        elif g == 2:\n",
    "            ind[2] = random.randrange(len(LAYERS_CHOICES))\n",
    "        elif g == 3:\n",
    "            ind[3] = random.randrange(len(DROPOUT_CHOICES))\n",
    "        elif g == 4:\n",
    "            ind[4] = random.randrange(len(BATCH_CHOICES))\n",
    "        elif g == 5:\n",
    "            ind[5] = random.randrange(len(BIDIR_CHOICES))\n",
    "        elif g == 7:\n",
    "            ind[7] = random.randrange(len(WD_CHOICES))\n",
    "        elif g == 8:\n",
    "            ind[8] = random.randrange(len(CLIP_CHOICES))\n",
    "        elif g == 9:\n",
    "            ind[9] = random.randrange(len(BOOL_CHOICES))\n",
    "        elif g == 10:\n",
    "            ind[10] = random.randrange(len(BOOL_CHOICES))\n",
    "    return ind\n",
    "\n",
    "def crossover(p1, p2, cx_rate):\n",
    "    \"Combine genetic material from two parent individuals (p1 and p2) to create two offspring.\"\n",
    "    if random.random() > cx_rate:\n",
    "        return p1[:], p2[:]\n",
    "    cut = random.randint(1, len(p1)-1)\n",
    "    return p1[:cut] + p2[cut:], p2[:cut] + p1[cut:]\n",
    "\n",
    "def tournament_select(pop, k=3):\n",
    "    \"select the fittest individuals to be parents for the next generation\"\n",
    "    cand = random.sample(pop, k)\n",
    "    cand.sort(key=lambda x: x[0])  # lower rmse better\n",
    "    return cand[0][1][:]\n",
    "\n",
    "# ===================== GA Objective (walk-forward CV) =====================\n",
    "def ga_objective(params, df, max_epochs, es_patience, cache):\n",
    "    key = tuple(sorted(params.items()))\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "\n",
    "    dfe = add_engineered_features(df, include_turbulence=params[\"turb_on\"])\n",
    "    if params[\"log_target\"]:\n",
    "        dfe[\"_y\"] = np.log1p(dfe[TARGET_COL].clip(lower=0)).astype(np.float32)\n",
    "    else:\n",
    "        dfe[\"_y\"] = dfe[TARGET_COL].astype(np.float32)\n",
    "    dfe = dfe.dropna().reset_index(drop=True)\n",
    "\n",
    "    feat_cols = build_feat_list(include_turbulence=params[\"turb_on\"])\n",
    "    X_all = dfe[feat_cols].to_numpy(np.float32)\n",
    "    y_all = dfe[[\"_y\"]].to_numpy(np.float32)\n",
    "\n",
    "    n_total = len(dfe)\n",
    "    n_test  = int(len(dfe) * (1 - (TRAIN_RATIO + VAL_RATIO)))  # last ≈15% as final Test\n",
    "    folds, _ = make_walkforward_indices(n_total, n_test)\n",
    "\n",
    "    fold_rmses = []\n",
    "    for (tr_s, tr_e, va_s, va_e) in folds:\n",
    "        Xtr = X_all[tr_s:tr_e]; ytr = y_all[tr_s:tr_e]\n",
    "        Xva = X_all[va_s:va_e]; yva = y_all[va_s:va_e]\n",
    "        pf = {k: params[k] for k in [\"lookback\",\"hidden\",\"layers\",\"dropout\",\"bidir\",\"batch\",\"lr\",\"wd\",\"clip\",\"log_target\"]}\n",
    "        rmse, _ = train_fold(Xtr, ytr, Xva, yva, pf, max_epochs, es_patience)\n",
    "        fold_rmses.append(rmse)\n",
    "\n",
    "    avg_rmse = float(np.mean(fold_rmses))\n",
    "    cache[key] = avg_rmse\n",
    "    return avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3db118",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'WindPowerForecastingData.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 152\u001b[39m\n\u001b[32m    149\u001b[39m args = ap.parse_args()\n\u001b[32m    151\u001b[39m outdir = Path(args.outdir); outdir.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m df = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWindPowerForecastingData.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# <— use CLI args\u001b[39;00m\n\u001b[32m    153\u001b[39m run_ga(df, pop=args.pop, gens=args.gens,\n\u001b[32m    154\u001b[39m         max_epochs=args.epochs, es_patience=args.patience,\n\u001b[32m    155\u001b[39m         seed=args.seed, outdir=outdir)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m(file_path: \u001b[38;5;28mstr\u001b[39m) -> pd.DataFrame:\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Uses CLI-provided path. Supports Excel/CSV.\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file_path.lower().endswith((\u001b[33m\"\u001b[39m\u001b[33m.xlsx\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.xls\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m         df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m         df = pd.read_csv(file_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LSTM/LSTM_Wind_assignment/LSTM/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LSTM/LSTM_Wind_assignment/LSTM/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LSTM/LSTM_Wind_assignment/LSTM/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LSTM/LSTM_Wind_assignment/LSTM/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'WindPowerForecastingData.xlsx'"
     ]
    }
   ],
   "source": [
    "# ===================== Final fit & test =====================\n",
    "def final_fit_and_test(df, best_params, max_epochs, es_patience, outdir: Path):\n",
    "    dfe = add_engineered_features(df, include_turbulence=best_params[\"turb_on\"])\n",
    "    if best_params[\"log_target\"]:\n",
    "        dfe[\"_y\"] = np.log1p(dfe[TARGET_COL].clip(lower=0)).astype(np.float32)\n",
    "    else:\n",
    "        dfe[\"_y\"] = dfe[TARGET_COL].astype(np.float32)\n",
    "    dfe = dfe.dropna().reset_index(drop=True)\n",
    "\n",
    "    feat_cols = build_feat_list(include_turbulence=best_params[\"turb_on\"])\n",
    "    X_all = dfe[feat_cols].to_numpy(np.float32)\n",
    "    y_all = dfe[[\"_y\"]].to_numpy(np.float32)\n",
    "\n",
    "    n_total = len(dfe)\n",
    "    n_test  = int(len(dfe) * (1 - (TRAIN_RATIO + VAL_RATIO)))\n",
    "    n_tv    = n_total - n_test\n",
    "    X_trval, y_trval = X_all[:n_tv], y_all[:n_tv]\n",
    "    X_test,  y_test  = X_all[n_tv:], y_all[n_tv:]\n",
    "\n",
    "    # scalers on Train+Val\n",
    "    xsc = StandardScaler().fit(X_trval)\n",
    "    ysc = StandardScaler().fit(y_trval)\n",
    "    Xtrv_s, ytrv_s = xsc.transform(X_trval), ysc.transform(y_trval)\n",
    "    Xte_s,  yte_s  = xsc.transform(X_test),  ysc.transform(y_test)\n",
    "\n",
    "    lookback = best_params[\"lookback\"]\n",
    "    Xtrv_seq, ytrv_seq = make_sequences(Xtrv_s, ytrv_s, lookback)\n",
    "    Xte_seq,  yte_seq  = make_sequences(Xte_s,  yte_s,  lookback)\n",
    "\n",
    "    mods = build_components(Xtrv_seq.shape[-1], best_params[\"hidden\"], best_params[\"layers\"],\n",
    "                            best_params[\"dropout\"], best_params[\"bidir\"])\n",
    "    opt  = optimizer_for(mods, best_params[\"lr\"], best_params[\"wd\"])\n",
    "    #sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=10, T_mult=2, eta_min=1e-5)\n",
    "    loss_fn = nn.SmoothL1Loss(beta=0.5)\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        set_train_mode(mods, True)\n",
    "        for xb, yb in batch_iter(Xtrv_seq, ytrv_seq, best_params[\"batch\"], shuffle=True):\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            pred = forward_pass(xb, mods, training=True)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            if best_params[\"clip\"] is not None:\n",
    "                nn.utils.clip_grad_norm_(\n",
    "                    list(mods[\"lstm\"].parameters()) + list(mods[\"lin1\"].parameters()) + list(mods[\"lin2\"].parameters()),\n",
    "                    best_params[\"clip\"]\n",
    "                )\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        #sched.step(epoch-1)\n",
    "\n",
    "    # evaluate on TEST (original units)\n",
    "    def inv_target(y_scaled):\n",
    "        ys = ysc.inverse_transform(y_scaled).ravel()\n",
    "        if best_params[\"log_target\"]:\n",
    "            ys = np.expm1(ys)\n",
    "        return ys\n",
    "\n",
    "    set_train_mode(mods, False)\n",
    "    preds_s, trues_s = [], []\n",
    "    for xb, yb in batch_iter(Xte_seq, yte_seq, best_params[\"batch\"], shuffle=False):\n",
    "        with torch.no_grad():\n",
    "            pr = forward_pass(xb.to(DEVICE), mods, training=False).cpu().numpy()\n",
    "        preds_s.append(pr); trues_s.append(yb.numpy())\n",
    "    preds_s = np.vstack(preds_s); trues_s = np.vstack(trues_s)\n",
    "    y_pred = inv_target(preds_s)\n",
    "    y_true = inv_target(trues_s)\n",
    "\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    smp  = smape(y_true, y_pred)\n",
    "\n",
    "    # save artifacts\n",
    "    torch.save({k: v.state_dict() for k, v in mods.items() if isinstance(v, nn.Module)}, outdir / \"bilstm_ga_best_noclass.pt\")\n",
    "    joblib.dump(xsc, outdir / \"x_scaler_ga.pkl\")\n",
    "    joblib.dump(ysc, outdir / \"y_scaler_ga.pkl\")\n",
    "    with open(outdir / \"best_params_ga.json\", \"w\") as f:\n",
    "        json.dump(best_params, f, indent=2)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(y_true, label=\"Actual\")\n",
    "    plt.plot(y_pred, label=\"Pred (GA best)\")\n",
    "    plt.title(\"BiLSTM + FE — Test (GA best, no-class)\")\n",
    "    plt.xlabel(\"Test time steps\"); plt.ylabel(TARGET_COL)\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(outdir / \"test_plot_ga.png\", dpi=150)\n",
    "\n",
    "    print(\"\\n==== TEST (GA best) ====\")\n",
    "    print(f\"RMSE : {rmse:.6f}\\nMAE  : {mae:.6f}\\nR^2  : {r2:.6f}\\nsMAPE: {smp:.2f}%\")\n",
    "    print(f\"Saved to: {outdir.resolve()}\")\n",
    "\n",
    "# ===================== GA Runner =====================\n",
    "def run_ga(df, pop=6, gens=3, cx_rate=0.6, mut_rate=0.25,\n",
    "           max_epochs=80, es_patience=12, seed=42, outdir=Path(\".\")):\n",
    "    set_seed(seed)\n",
    "    fitness_cache = {}\n",
    "\n",
    "    # init population\n",
    "    pop_list = []\n",
    "    for i in range(pop):\n",
    "        ind = random_individual()\n",
    "        params = decode(ind)\n",
    "        fit = ga_objective(params, df, max_epochs, es_patience, fitness_cache)\n",
    "        pop_list.append((fit, ind))\n",
    "        print(f\"Init {i+1}/{pop}: RMSE={fit:.5f} | {params}\")\n",
    "\n",
    "    best = min(pop_list, key=lambda x: x[0])\n",
    "    print(f\"\\nGen 0 best: RMSE={best[0]:.5f} | {decode(best[1])}\")\n",
    "\n",
    "    # evolve\n",
    "    for g in range(1, gens+1):\n",
    "        new_pop = sorted(pop_list, key=lambda x: x[0])[:2]  # elitism\n",
    "        while len(new_pop) < pop:\n",
    "            p1 = tournament_select(pop_list, k=3)\n",
    "            p2 = tournament_select(pop_list, k=3)\n",
    "            c1, c2 = crossover(p1, p2, cx_rate)\n",
    "            c1 = mutate(c1, mut_rate); c2 = mutate(c2, mut_rate)\n",
    "            for child in [c1, c2]:\n",
    "                params = decode(child)\n",
    "                fit = ga_objective(params, df, max_epochs, es_patience, fitness_cache)\n",
    "                new_pop.append((fit, child))\n",
    "                print(f\"[Gen {g}] cand -> RMSE={fit:.5f} | {params}\")\n",
    "                if len(new_pop) >= pop: break\n",
    "        pop_list = new_pop\n",
    "        best = min(pop_list, key=lambda x: x[0])\n",
    "        print(f\"Gen {g} best: RMSE={best[0]:.5f} | {decode(best[1])}\")\n",
    "\n",
    "    best_fit, best_ind = min(pop_list, key=lambda x: x[0])\n",
    "    best_params = decode(best_ind)\n",
    "    print(\"\\n==== GA RESULT ====\")\n",
    "    print(f\"Best Val RMSE: {best_fit:.6f}\")\n",
    "    print(\"Best Params:\", best_params)\n",
    "\n",
    "    final_fit_and_test(df, best_params, max_epochs, es_patience, outdir)\n",
    "    return best_params\n",
    "\n",
    "# ===================== CLI =====================\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"--file\",   type=str, required=True)\n",
    "ap.add_argument(\"--sheet\",  type=str, default=None)\n",
    "ap.add_argument(\"--pop\",    type=int, default=12)   # smaller defaults to speed up\n",
    "ap.add_argument(\"--gens\",   type=int, default=6)\n",
    "ap.add_argument(\"--epochs\", type=int, default=60)\n",
    "ap.add_argument(\"--patience\", type=int, default=10)\n",
    "ap.add_argument(\"--seed\",   type=int, default=42)\n",
    "ap.add_argument(\"--outdir\", type=str, default=\".\")\n",
    "args = ap.parse_args()\n",
    "\n",
    "outdir = Path(args.outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "df = load_data(\"WindPowerForecastingData.xlsx\")  # <— use CLI args\n",
    "run_ga(df, pop=args.pop, gens=args.gens,\n",
    "        max_epochs=args.epochs, es_patience=args.patience,\n",
    "        seed=args.seed, outdir=outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247f2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
