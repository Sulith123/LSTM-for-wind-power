{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3b945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_step_from_24.py\n",
    "import json, numpy as np, pandas as pd, torch, torch.nn as nn, joblib\n",
    "from pathlib import Path\n",
    "\n",
    "TIME_COL   = \"TIMESTAMP\"\n",
    "TARGET_COL = \"TARGETVAR\"\n",
    "BASE_FEATS = [\"U10\",\"V10\",\"U100\",\"V100\"]\n",
    "LAGS_Y     = [1,3,6,12,24]\n",
    "LAGS_SPEED = [1,3,6]\n",
    "ROLLS_Y    = [6,12,24]\n",
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def add_engineered_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"speed10\"]  = np.sqrt(out[\"U10\"]**2  + out[\"V10\"]**2)\n",
    "    out[\"speed100\"] = np.sqrt(out[\"U100\"]**2 + out[\"V100\"]**2)\n",
    "    d10  = np.arctan2(out[\"V10\"],  out[\"U10\"])\n",
    "    d100 = np.arctan2(out[\"V100\"], out[\"U100\"])\n",
    "    out[\"dir10_sin\"], out[\"dir10_cos\"]   = np.sin(d10),  np.cos(d10)\n",
    "    out[\"dir100_sin\"], out[\"dir100_cos\"] = np.sin(d100), np.cos(d100)\n",
    "    out[\"shear_speed\"] = out[\"speed100\"] - out[\"speed10\"]\n",
    "    veer = d100 - d10\n",
    "    out[\"veer_sin\"], out[\"veer_cos\"] = np.sin(veer), np.cos(veer)\n",
    "    out[\"hour\"] = pd.to_datetime(out[TIME_COL]).dt.hour\n",
    "    out[\"day\"]  = pd.to_datetime(out[TIME_COL]).dt.dayofyear\n",
    "    out[\"hour_sin\"] = np.sin(2*np.pi*out[\"hour\"]/24.0)\n",
    "    out[\"hour_cos\"] = np.cos(2*np.pi*out[\"hour\"]/24.0)\n",
    "    out[\"day_sin\"]  = np.sin(2*np.pi*out[\"day\"]/366.0)\n",
    "    out[\"day_cos\"]  = np.cos(2*np.pi*out[\"day\"]/366.0)\n",
    "    for L in LAGS_Y:\n",
    "        out[f\"y_lag{L}\"] = out[TARGET_COL].shift(L)\n",
    "    for W in ROLLS_Y:\n",
    "        out[f\"y_roll{W}\"] = out[TARGET_COL].shift(1).rolling(W, min_periods=W).mean()\n",
    "    for L in LAGS_SPEED:\n",
    "        out[f\"speed10_lag{L}\"]  = out[\"speed10\"].shift(L)\n",
    "        out[f\"speed100_lag{L}\"] = out[\"speed100\"].shift(L)\n",
    "    return out\n",
    "\n",
    "def build_feat_list():\n",
    "    return (\n",
    "        BASE_FEATS +\n",
    "        [\"speed10\",\"speed100\",\"dir10_sin\",\"dir10_cos\",\"dir100_sin\",\"dir100_cos\",\n",
    "         \"shear_speed\",\"veer_sin\",\"veer_cos\",\"hour_sin\",\"hour_cos\",\"day_sin\",\"day_cos\"] +\n",
    "        [f\"y_lag{L}\" for L in LAGS_Y] +\n",
    "        [f\"y_roll{W}\" for W in ROLLS_Y] +\n",
    "        [f\"speed10_lag{L}\" for L in LAGS_SPEED] +\n",
    "        [f\"speed100_lag{L}\" for L in LAGS_SPEED]\n",
    "    )\n",
    "\n",
    "class BiLSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "            batch_first=True, dropout=dropout if num_layers>1 else 0.0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        out_size = hidden_size * (2 if bidirectional else 1)\n",
    "        self.norm = nn.LayerNorm(out_size)\n",
    "        self.head = nn.Sequential(nn.Linear(out_size, out_size), nn.GELU(), nn.Dropout(dropout), nn.Linear(out_size,1))\n",
    "    def forward(self, x):\n",
    "        o,_ = self.lstm(x); last = self.norm(o[:, -1, :]); return self.head(last)\n",
    "\n",
    "def load_artifacts(model_root: str):\n",
    "    root = Path(model_root)\n",
    "    with open(root / \"../biLSTM/best_params.json\",\"r\") as f: best_params = json.load(f)\n",
    "    xsc = joblib.load(root / \"../biLSTM/x_scaler_optuna.pkl\")\n",
    "    ysc = joblib.load(root / \"../biLSTM/y_scaler_optuna.pkl\")\n",
    "    state = torch.load(root / \"../biLSTM/bilstm_optuna_best.pt\", map_location=DEVICE)\n",
    "    return best_params, xsc, ysc, state\n",
    "\n",
    "def predict_next_from_last24(model_root: str, last24_df: pd.DataFrame, future_weather: dict|None=None):\n",
    "    \"\"\"\n",
    "    last24_df: DataFrame with at least 24 recent rows and columns:\n",
    "        TIMESTAMP, TARGETVAR, U10, V10, U100, V100 (same units/schema as training).\n",
    "    future_weather (optional): dict with keys 'U10','V10','U100','V100' for the *next* hour.\n",
    "        If provided, we’ll use these exogenous values for the t+1 features.\n",
    "        If None, we 'hold' the last known exogenous values.\n",
    "    \"\"\"\n",
    "    best, xsc, ysc, state = load_artifacts(model_root)\n",
    "\n",
    "    df = last24_df.copy().sort_values(TIME_COL).reset_index(drop=True)\n",
    "\n",
    "    # If the model’s lookback > provided rows, we can’t predict\n",
    "    lookback = int(best[\"lookback\"])\n",
    "    if len(df) < lookback:\n",
    "        raise ValueError(f\"Need at least {lookback} rows of history; got {len(df)}.\")\n",
    "\n",
    "    # Optionally append a synthetic next-hour exogenous row (same timestamp +1h)\n",
    "    if future_weather is None:\n",
    "        fut = df.iloc[[-1]][[TIME_COL]+BASE_FEATS].copy()\n",
    "        fut[TIME_COL] = pd.to_datetime(fut[TIME_COL]) + pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        fut = pd.DataFrame([{\n",
    "            TIME_COL: pd.to_datetime(df[TIME_COL].iloc[-1]) + pd.Timedelta(hours=1),\n",
    "            \"U10\": future_weather[\"U10\"], \"V10\": future_weather[\"V10\"],\n",
    "            \"U100\": future_weather[\"U100\"], \"V100\": future_weather[\"V100\"],\n",
    "        }])\n",
    "    # set TARGETVAR for the future row temporarily with NaN; we’ll fill it using lags after FE\n",
    "    fut[TARGET_COL] = np.nan\n",
    "\n",
    "    # Build a small working frame = history + placeholder next hour\n",
    "    work = pd.concat([df[[TIME_COL, TARGET_COL]+BASE_FEATS], fut], ignore_index=True)\n",
    "\n",
    "    # For engineered y-lag/roll features, we need actual history TARGETVAR (available in df).\n",
    "    # After FE, the last row will have all lags computed from history; TARGETVAR itself is NaN for that last row.\n",
    "    dfe = add_engineered_features(work)\n",
    "\n",
    "    # Drop only rows that are still incomplete *before* the last row\n",
    "    dfe_hist = dfe.iloc[:-1].dropna().copy()\n",
    "    if len(dfe_hist) < lookback:\n",
    "        raise ValueError(f\"After feature lags/rolls, not enough rows to form a {lookback}-step window. \"\n",
    "                         f\"Provide a bit more history (≥ {lookback+1} rows).\")\n",
    "\n",
    "    # The final feature row we’ll predict on is the very last row (t+1), which has complete lags from history\n",
    "    feat_cols = build_feat_list()\n",
    "    X_hist = dfe_hist[feat_cols].to_numpy(np.float32)\n",
    "\n",
    "    # scale with training scalers\n",
    "    X_hist_s = xsc.transform(X_hist)\n",
    "\n",
    "    # Build the input window (last `lookback` rows)\n",
    "    X_window = X_hist_s[-lookback:, :]                       # shape (lookback, n_feats)\n",
    "    xb = torch.from_numpy(X_window[None, ...]).float().to(DEVICE)\n",
    "\n",
    "    # Rebuild model & load weights\n",
    "    model = BiLSTMRegressor(\n",
    "        input_size=X_window.shape[-1],\n",
    "        hidden_size=int(best[\"hidden\"]),\n",
    "        num_layers=int(best[\"layers\"]),\n",
    "        dropout=float(best[\"dropout\"]),\n",
    "        bidirectional=bool(best[\"bidir\"])\n",
    "    ).to(DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        yhat_s = model(xb).cpu().numpy()                    # scaled\n",
    "    # Invert scaling (and log if used)\n",
    "    yhat = ysc.inverse_transform(yhat_s).ravel()[0]\n",
    "    if bool(best[\"log_target\"]):\n",
    "        yhat = np.expm1(yhat)\n",
    "\n",
    "    next_ts = pd.to_datetime(df[TIME_COL].iloc[-1]) + pd.Timedelta(hours=1)\n",
    "    return next_ts, float(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5849ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-01 10:00:00 0.1537948101758957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Put your last 24 rows into a DataFrame:\n",
    "# Must have columns: TIMESTAMP, TARGETVAR, U10, V10, U100, V100\n",
    "last24 = pd.read_csv(\"my_last_24.csv\")  # or build manually\n",
    "\n",
    "# 2) If you already know the next hour’s weather, pass it (optional):\n",
    "future_weather = {\n",
    "    \"U10\": 3.5, \"V10\": -1.2,\n",
    "    \"U100\": 5.1, \"V100\": -1.8\n",
    "}\n",
    "# If you don’t know it, set future_weather=None (the code will hold the last known values)\n",
    "\n",
    "# 3) Predict the next hour:\n",
    "next_ts, y_pred = predict_next_from_last24(\n",
    "    model_root=\".\",            # folder with best_params.json + biLSTM/*\n",
    "    last24_df=last24,\n",
    "    future_weather=None        # or future_weather dict as above\n",
    ")\n",
    "print(next_ts, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
