{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff80a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4613067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 35 rows with missing target.\n",
      "   TARGETVAR       U10       V10      U100      V100\n",
      "0   0.000000  2.124600 -2.681966  2.864280 -3.666076\n",
      "1   0.054879  2.521695 -1.796960  3.344859 -2.464761\n",
      "2   0.110234  2.672210 -0.822516  3.508448 -1.214093\n",
      "3   0.165116  2.457504 -0.143642  3.215233 -0.355546\n",
      "4   0.156940  2.245898  0.389576  2.957678  0.332701\n",
      ".......................\n",
      "       TARGETVAR\n",
      "0       0.000000\n",
      "1       0.054879\n",
      "2       0.110234\n",
      "3       0.165116\n",
      "4       0.156940\n",
      "...          ...\n",
      "16771   0.034301\n",
      "16772   0.104407\n",
      "16773   0.114839\n",
      "16774   0.162579\n",
      "16775   0.096232\n",
      "\n",
      "[16765 rows x 1 columns]\n",
      ".....y train ..................\n",
      "[[0.        ]\n",
      " [0.05487912]\n",
      " [0.110234  ]\n",
      " ...\n",
      " [0.11483883]\n",
      " [0.1625787 ]\n",
      " [0.09623155]]\n",
      ".....x train ..................\n",
      "[[ 2.12460014 -2.68196637  2.86427959 -3.66607576]\n",
      " [ 2.52169465 -1.79696009  3.34485867 -2.46476146]\n",
      " [ 2.67220986 -0.82251622  3.50844802 -1.21409294]\n",
      " ...\n",
      " [-3.43336055  2.45759889 -4.79611597  3.40720263]\n",
      " [-3.22426125  2.04905457 -4.40783408  2.75519536]\n",
      " [-2.86935323  1.68596145 -3.87123168  2.20045256]]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Load & clean\n",
    "# =========================\n",
    "df = pd.read_excel(\"./WindPowerForecastingData.xlsx\")\n",
    "df[\"DATETIME\"] = pd.to_datetime(df[\"TIMESTAMP\"], format=\"%Y%m%d %H:%M\", errors=\"coerce\")\n",
    "df = df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "\n",
    "TARGET_COL = \"TARGETVAR\"  # change this to actual target column name\n",
    "df_clean = df.drop(columns=[c for c in [\"TIMESTAMP\",\"DATETIME\"] if c in df.columns]).copy()\n",
    "cols = [TARGET_COL] + [c for c in df_clean.columns if c != TARGET_COL]\n",
    "df_clean = df_clean[cols].astype(float)\n",
    "\n",
    "##############3\n",
    "n_before = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=[TARGET_COL]).copy()\n",
    "print(f\"Dropped {n_before - len(df_clean)} rows with missing target.\")\n",
    "##############\n",
    "\n",
    "print (df_clean.head())\n",
    "# =========================\n",
    "# 2) Chronological split\n",
    "# =========================\n",
    "n = len(df_clean)\n",
    "train_n = int(1 * n)\n",
    "train_df = df_clean.iloc[:train_n].copy()\n",
    "test_df  = df_clean.iloc[train_n:].copy()\n",
    "print(\".......................\")\n",
    "print(train_df[[TARGET_COL]])\n",
    "y_train = train_df[[TARGET_COL]].values\n",
    "print(\".....y train ..................\")\n",
    "print(y_train)\n",
    "X_train = train_df.drop(columns=[TARGET_COL]).values\n",
    "print(\".....x train ..................\")\n",
    "print(X_train)\n",
    "y_test  = test_df[[TARGET_COL]].values\n",
    "X_test  = test_df.drop(columns=[TARGET_COL]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01db05",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torch.nn.modules.rnn.LSTM was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torch.nn.modules.rnn.LSTM])` or the `torch.serialization.safe_globals([torch.nn.modules.rnn.LSTM])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load the full model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# model.eval()\u001b[39;00m\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Convert data to tensor\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LSTM/LSTM_Wind_assignment/LSTM/lib/python3.12/site-packages/torch/serialization.py:1529\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1521\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1522\u001b[39m                     opened_zipfile,\n\u001b[32m   1523\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1526\u001b[39m                     **pickle_load_args,\n\u001b[32m   1527\u001b[39m                 )\n\u001b[32m   1528\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1529\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1530\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1531\u001b[39m             opened_zipfile,\n\u001b[32m   1532\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1535\u001b[39m             **pickle_load_args,\n\u001b[32m   1536\u001b[39m         )\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torch.nn.modules.rnn.LSTM was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torch.nn.modules.rnn.LSTM])` or the `torch.serialization.safe_globals([torch.nn.modules.rnn.LSTM])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Load the full model\n",
    "model = torch.load(\"glstm_noclass_best.pth\")\n",
    "print(model)\n",
    "# model.eval()\n",
    "\n",
    "# Convert data to tensor\n",
    "X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# Run predictions\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_tensor).squeeze().numpy()\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = math.sqrt(mean_squared_error(y, y_pred))\n",
    "print(f\"RMSE on entire dataset: {rmse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
